#!/usr/bin/env python3
"""
Labyrinthia AI - ç®€åŒ–ä»£ç†æµ‹è¯•
Simple proxy test for the Labyrinthia AI game
"""

import requests
import sys
import time
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from config import config


def test_proxy_gemini():
    """æµ‹è¯•é€šè¿‡ä»£ç†è¿æ¥Gemini API"""
    print(f"ğŸ¤– æµ‹è¯•é€šè¿‡ä»£ç†è¿æ¥Gemini API...")
    print(f"   ä»£ç†: {config.llm.proxy_url}")
    print(f"   APIå¯†é’¥: {config.llm.api_key[:10]}...{config.llm.api_key[-4:]}")
    
    try:
        url = "https://generativelanguage.googleapis.com/v1beta/models"
        params = {"key": config.llm.api_key}
        proxies = {
            'http': config.llm.proxy_url,
            'https': config.llm.proxy_url
        }
        
        print("   æ­£åœ¨è¿æ¥...")
        start_time = time.time()
        response = requests.get(url, params=params, proxies=proxies, timeout=15)
        end_time = time.time()
        
        if response.status_code == 200:
            data = response.json()
            models = data.get('models', [])
            print(f"âœ… è¿æ¥æˆåŠŸï¼(è€—æ—¶: {end_time - start_time:.2f}ç§’)")
            print(f"   å¯ç”¨æ¨¡å‹æ•°é‡: {len(models)}")
            if models:
                print(f"   ç¤ºä¾‹æ¨¡å‹: {models[0].get('name', 'unknown')}")
            return True
        else:
            print(f"âŒ è¿æ¥å¤±è´¥: HTTP {response.status_code}")
            print(f"   å“åº”: {response.text[:200]}")
            return False
            
    except requests.exceptions.Timeout:
        print("âŒ è¿æ¥è¶…æ—¶")
        return False
    except requests.exceptions.ProxyError as e:
        print(f"âŒ ä»£ç†é”™è¯¯: {e}")
        return False
    except requests.exceptions.ConnectionError as e:
        print(f"âŒ è¿æ¥é”™è¯¯: {e}")
        return False
    except Exception as e:
        print(f"âŒ å…¶ä»–é”™è¯¯: {e}")
        return False


def test_gemini_generate():
    """æµ‹è¯•Geminiæ–‡æœ¬ç”Ÿæˆ"""
    print("ğŸ¯ æµ‹è¯•Geminiæ–‡æœ¬ç”Ÿæˆ...")
    
    try:
        from gemini_api import GeminiAPI
        
        # å‡†å¤‡ä»£ç†é…ç½®
        proxies = {
            'http': config.llm.proxy_url,
            'https': config.llm.proxy_url
        }
        
        # åˆ›å»ºAPIå®¢æˆ·ç«¯
        client = GeminiAPI(
            api_key=config.llm.api_key,
            proxies=proxies
        )
        
        print("   æ­£åœ¨ç”Ÿæˆæ–‡æœ¬...")
        start_time = time.time()
        response = client.single_turn(
            text="è¯·ç®€çŸ­å›å¤ï¼šä½ å¥½ï¼Œæˆ‘æ˜¯Labyrinthia AIæ¸¸æˆï¼",
            generation_config={"max_output_tokens": 100}
        )
        end_time = time.time()
        
        if response.get("candidates"):
            candidate = response["candidates"][0]
            content = candidate.get("content", {})
            parts = content.get("parts", [])

            if parts and parts[0].get("text"):
                text = parts[0]["text"].strip()
                print(f"âœ… æ–‡æœ¬ç”ŸæˆæˆåŠŸï¼(è€—æ—¶: {end_time - start_time:.2f}ç§’)")
                print(f"   AIå›å¤: {text}")
                return True
            else:
                # æ£€æŸ¥æ˜¯å¦å› ä¸ºMAX_TOKENSè€Œè¢«æˆªæ–­
                finish_reason = candidate.get("finishReason", "")
                if finish_reason == "MAX_TOKENS":
                    print("âš ï¸  æ–‡æœ¬ç”Ÿæˆè¢«æˆªæ–­ï¼ˆè¾¾åˆ°æœ€å¤§tokené™åˆ¶ï¼‰ï¼Œä½†è¿æ¥æ­£å¸¸")
                    print(f"   å®ŒæˆåŸå› : {finish_reason}")
                    print("âœ… ä»£ç†å’ŒAPIè¿æ¥æ­£å¸¸å·¥ä½œï¼")
                    return True
                else:
                    print("âŒ æ–‡æœ¬ç”Ÿæˆå¤±è´¥ï¼šå“åº”æ ¼å¼å¼‚å¸¸")
                    print(f"   å®ŒæˆåŸå› : {finish_reason}")
                    print(f"   åŸå§‹å“åº”: {response}")
                    return False

        print("âŒ æ–‡æœ¬ç”Ÿæˆå¤±è´¥ï¼šæ— å€™é€‰å“åº”")
        print(f"   åŸå§‹å“åº”: {response}")
        return False
        
    except Exception as e:
        print(f"âŒ æ–‡æœ¬ç”Ÿæˆé”™è¯¯: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ° Labyrinthia AI - ç®€åŒ–ä»£ç†æµ‹è¯•")
    print("=" * 50)
    
    # æ£€æŸ¥é…ç½®
    if not config.llm.api_key or config.llm.api_key == "your-api-key-here":
        print("âŒ è¯·å…ˆè®¾ç½®Gemini APIå¯†é’¥")
        sys.exit(1)
    
    if not config.llm.use_proxy or not config.llm.proxy_url:
        print("âŒ è¯·å¯ç”¨å¹¶é…ç½®ä»£ç†")
        sys.exit(1)
    
    # è¿è¡Œæµ‹è¯•
    tests = [
        test_proxy_gemini,
        test_gemini_generate
    ]
    
    passed = 0
    for test_func in tests:
        try:
            if test_func():
                passed += 1
            print()
        except KeyboardInterrupt:
            print("\nğŸ›‘ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
            sys.exit(1)
        except Exception as e:
            print(f"   æµ‹è¯•å¼‚å¸¸: {e}")
            print()
    
    print("=" * 50)
    if passed == len(tests):
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ä»£ç†é…ç½®æ­£å¸¸ï¼Œå¯ä»¥å¼€å§‹æ¸¸æˆäº†ï¼")
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»£ç†é…ç½®")


if __name__ == "__main__":
    main()
